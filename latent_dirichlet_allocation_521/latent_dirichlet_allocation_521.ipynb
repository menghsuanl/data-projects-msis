{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ae795a",
   "metadata": {},
   "source": [
    "There are 1000 reviews for restaurants and films in a collection under the IA3-2.csv file. All of those reviews are saved as text files. In this assignment, you are required to investigate the topics of those reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "207c6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "eb42c506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>About the shop: There is a restaurant in Soi L...</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>About the shop: Through this store for about t...</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Roast Coffee &amp;amp; Eatery is a restaurant loca...</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Eat from the children. The shop is opposite. P...</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Ak 1 shop at another branch tastes the sam...</td>\n",
       "      <td>restaurant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review       label\n",
       "0   1  About the shop: There is a restaurant in Soi L...  restaurant\n",
       "1   2  About the shop: Through this store for about t...  restaurant\n",
       "2   3  Roast Coffee &amp; Eatery is a restaurant loca...  restaurant\n",
       "3   4  Eat from the children. The shop is opposite. P...  restaurant\n",
       "4   5  The Ak 1 shop at another branch tastes the sam...  restaurant"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('IA3-2.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f4b17c",
   "metadata": {},
   "source": [
    "## 1. Transform those reviews into a term-document matrix, lemmatize all the words, remove the stop-words and punctuations, set the minimal document frequency for each term to be 5 and include 2-gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "508520a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize, remove stop-words\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "processed_review = []\n",
    "for doc in df['review']:\n",
    "    tokens = nltk.word_tokenize(doc.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha()]\n",
    "    tokens = [token for token in tokens if not token in stopwords.words('english')]\n",
    "    processed_review.append(\" \".join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b42b2106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.13698245 ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Use TFIDF to set the minimal document frequency for each term to be 5 and include 2-gram\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df = 5)\n",
    "vectorizer.fit(processed_review)\n",
    "X = vectorizer.transform(processed_review)\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba92267",
   "metadata": {},
   "source": [
    "## 2. Use the LDA model to extract the topics of each document. In particular, we assume there are 6 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "2c95d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=6).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "44e9c967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.28920483, 1.36559168, 2.19168414, ..., 0.35056112, 2.3615017 ,\n",
       "        0.21554325],\n",
       "       [0.16667049, 0.16666892, 0.1666688 , ..., 0.16667155, 0.16668615,\n",
       "        0.16667888],\n",
       "       [0.16667054, 0.16666895, 0.16666883, ..., 0.16667162, 0.1666864 ,\n",
       "        0.16667904],\n",
       "       [0.16667054, 0.16666895, 0.16666883, ..., 0.16667162, 0.16668641,\n",
       "        0.16667904],\n",
       "       [0.1666701 , 0.1666674 , 0.16668607, ..., 0.16687853, 0.24384703,\n",
       "        4.41711932],\n",
       "       [0.16667053, 0.16666894, 0.16666883, ..., 0.1666716 , 0.16668635,\n",
       "        0.16667901]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_ # counts(prob) of word j to appear in topic i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "cedf19d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6258)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0d818382",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29cf75e",
   "metadata": {},
   "source": [
    "## 3. Report the topic distribution and the top-2 topics of the first 10 restaurant reviews (id = [1:10]) and the first 10 movie reviews (id = [501:510])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "6ee5dbda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01567623, 0.15112103, 0.01558031, 0.01558032, 0.7864618 ,\n",
       "        0.01558031],\n",
       "       [0.01759481, 0.18356539, 0.01576118, 0.01576118, 0.75152571,\n",
       "        0.01579174],\n",
       "       [0.01564439, 0.01539142, 0.01539131, 0.01539131, 0.92279027,\n",
       "        0.0153913 ],\n",
       "       [0.24464539, 0.01947687, 0.01947691, 0.01947691, 0.67744704,\n",
       "        0.0194769 ],\n",
       "       [0.19124413, 0.02767625, 0.0276763 , 0.02767631, 0.69805072,\n",
       "        0.02767629],\n",
       "       [0.01676469, 0.01647329, 0.01647172, 0.01647172, 0.91734687,\n",
       "        0.01647171],\n",
       "       [0.01884125, 0.01820465, 0.01820468, 0.01820468, 0.90834007,\n",
       "        0.01820467],\n",
       "       [0.01927809, 0.01921875, 0.01921877, 0.01921877, 0.90384684,\n",
       "        0.01921877],\n",
       "       [0.04475409, 0.04472161, 0.04472162, 0.04472162, 0.77635944,\n",
       "        0.04472162],\n",
       "       [0.04110911, 0.04050126, 0.04050136, 0.04050136, 0.79688477,\n",
       "        0.04050214]])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 10 restaurant reviews\n",
    "lda.transform(X[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8408099e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review ID 1\n",
      "Topic 0: 0.016 , Topic 1: 0.151 , Topic 2: 0.016 , Topic 3: 0.016 , Topic 4: 0.786 , Topic 5: 0.016 , \n",
      "-----------\n",
      "Review ID 2\n",
      "Topic 0: 0.018 , Topic 1: 0.184 , Topic 2: 0.016 , Topic 3: 0.016 , Topic 4: 0.752 , Topic 5: 0.016 , \n",
      "-----------\n",
      "Review ID 3\n",
      "Topic 0: 0.016 , Topic 1: 0.015 , Topic 2: 0.015 , Topic 3: 0.015 , Topic 4: 0.923 , Topic 5: 0.015 , \n",
      "-----------\n",
      "Review ID 4\n",
      "Topic 0: 0.245 , Topic 1: 0.019 , Topic 2: 0.019 , Topic 3: 0.019 , Topic 4: 0.677 , Topic 5: 0.019 , \n",
      "-----------\n",
      "Review ID 5\n",
      "Topic 0: 0.191 , Topic 1: 0.028 , Topic 2: 0.028 , Topic 3: 0.028 , Topic 4: 0.698 , Topic 5: 0.028 , \n",
      "-----------\n",
      "Review ID 6\n",
      "Topic 0: 0.017 , Topic 1: 0.016 , Topic 2: 0.016 , Topic 3: 0.016 , Topic 4: 0.917 , Topic 5: 0.016 , \n",
      "-----------\n",
      "Review ID 7\n",
      "Topic 0: 0.019 , Topic 1: 0.018 , Topic 2: 0.018 , Topic 3: 0.018 , Topic 4: 0.908 , Topic 5: 0.018 , \n",
      "-----------\n",
      "Review ID 8\n",
      "Topic 0: 0.019 , Topic 1: 0.019 , Topic 2: 0.019 , Topic 3: 0.019 , Topic 4: 0.904 , Topic 5: 0.019 , \n",
      "-----------\n",
      "Review ID 9\n",
      "Topic 0: 0.045 , Topic 1: 0.045 , Topic 2: 0.045 , Topic 3: 0.045 , Topic 4: 0.776 , Topic 5: 0.045 , \n",
      "-----------\n",
      "Review ID 10\n",
      "Topic 0: 0.041 , Topic 1: 0.041 , Topic 2: 0.041 , Topic 3: 0.041 , Topic 4: 0.797 , Topic 5: 0.041 , \n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Distribution of  each topic: probabilities of topics rounded to 3 decimals\n",
    "for i in range(0,10):\n",
    "    id = i+1\n",
    "    print('Review ID %d' %id)\n",
    "    for j in range(0,6):\n",
    "        print('Topic '+str(j)+':', round(lda.transform(X[0:10])[i][j], 3),str(','), end=' ')\n",
    "    print()\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0e2fee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review ID 1\n",
      "Top 1: 4 Top 2: 1\n",
      "-----------\n",
      "Review ID 2\n",
      "Top 1: 4 Top 2: 1\n",
      "-----------\n",
      "Review ID 3\n",
      "Top 1: 4 Top 2: 0\n",
      "-----------\n",
      "Review ID 4\n",
      "Top 1: 4 Top 2: 0\n",
      "-----------\n",
      "Review ID 5\n",
      "Top 1: 4 Top 2: 0\n",
      "-----------\n",
      "Review ID 6\n",
      "Top 1: 4 Top 2: 0\n",
      "-----------\n",
      "Review ID 7\n",
      "Top 1: 4 Top 2: 0\n",
      "-----------\n",
      "Review ID 8\n",
      "Top 1: 4 Top 2: 0\n",
      "-----------\n",
      "Review ID 9\n",
      "Top 1: 4 Top 2: 0\n",
      "-----------\n",
      "Review ID 10\n",
      "Top 1: 4 Top 2: 0\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Top 2 topics of each review(reported by topic number)\n",
    "for i in range(0,10):\n",
    "    id = i+1\n",
    "    print('Review ID %d' %id)\n",
    "    t2, t1 = lda.transform(X[0:10])[i].argsort()[-2:]\n",
    "    print('Top 1:', t1,'Top 2:', t2)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "61119c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review ID 501\n",
      "Topic 0: 0.918 , Topic 1: 0.016 , Topic 2: 0.016 , Topic 3: 0.016 , Topic 4: 0.016 , Topic 5: 0.016 , \n",
      "-----------\n",
      "Review ID 502\n",
      "Topic 0: 0.927 , Topic 1: 0.012 , Topic 2: 0.012 , Topic 3: 0.012 , Topic 4: 0.024 , Topic 5: 0.012 , \n",
      "-----------\n",
      "Review ID 503\n",
      "Topic 0: 0.944 , Topic 1: 0.011 , Topic 2: 0.011 , Topic 3: 0.011 , Topic 4: 0.011 , Topic 5: 0.011 , \n",
      "-----------\n",
      "Review ID 504\n",
      "Topic 0: 0.862 , Topic 1: 0.028 , Topic 2: 0.028 , Topic 3: 0.028 , Topic 4: 0.028 , Topic 5: 0.028 , \n",
      "-----------\n",
      "Review ID 505\n",
      "Topic 0: 0.924 , Topic 1: 0.015 , Topic 2: 0.015 , Topic 3: 0.015 , Topic 4: 0.015 , Topic 5: 0.015 , \n",
      "-----------\n",
      "Review ID 506\n",
      "Topic 0: 0.915 , Topic 1: 0.017 , Topic 2: 0.017 , Topic 3: 0.017 , Topic 4: 0.017 , Topic 5: 0.017 , \n",
      "-----------\n",
      "Review ID 507\n",
      "Topic 0: 0.91 , Topic 1: 0.018 , Topic 2: 0.018 , Topic 3: 0.018 , Topic 4: 0.018 , Topic 5: 0.018 , \n",
      "-----------\n",
      "Review ID 508\n",
      "Topic 0: 0.857 , Topic 1: 0.029 , Topic 2: 0.029 , Topic 3: 0.029 , Topic 4: 0.029 , Topic 5: 0.029 , \n",
      "-----------\n",
      "Review ID 509\n",
      "Topic 0: 0.941 , Topic 1: 0.012 , Topic 2: 0.012 , Topic 3: 0.012 , Topic 4: 0.012 , Topic 5: 0.012 , \n",
      "-----------\n",
      "Review ID 510\n",
      "Topic 0: 0.931 , Topic 1: 0.014 , Topic 2: 0.013 , Topic 3: 0.013 , Topic 4: 0.015 , Topic 5: 0.013 , \n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# First 10 movie reviews\n",
    "lda.transform(X[500:510])\n",
    "\n",
    "# Distribution of  each topic: probabilities of topics rounded to 3 decimals\n",
    "for i in range(0,10):\n",
    "    id = i+501\n",
    "    print('Review ID %d' %id)\n",
    "    for j in range(0,6):\n",
    "        print('Topic '+str(j)+':', round(lda.transform(X[500:510])[i][j], 3),str(','), end=' ')\n",
    "    print()\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "571677db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review ID 501\n",
      "Top 1: 0 Top 2: 4\n",
      "-----------\n",
      "Review ID 502\n",
      "Top 1: 0 Top 2: 4\n",
      "-----------\n",
      "Review ID 503\n",
      "Top 1: 0 Top 2: 4\n",
      "-----------\n",
      "Review ID 504\n",
      "Top 1: 0 Top 2: 4\n",
      "-----------\n",
      "Review ID 505\n",
      "Top 1: 0 Top 2: 4\n",
      "-----------\n",
      "Review ID 506\n",
      "Top 1: 0 Top 2: 4\n",
      "-----------\n",
      "Review ID 507\n",
      "Top 1: 0 Top 2: 4\n",
      "-----------\n",
      "Review ID 508\n",
      "Top 1: 0 Top 2: 4\n",
      "-----------\n",
      "Review ID 509\n",
      "Top 1: 0 Top 2: 4\n",
      "-----------\n",
      "Review ID 510\n",
      "Top 1: 0 Top 2: 4\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "# Top 2 topics of each review(reported by topic number)\n",
    "for i in range(0,10):\n",
    "    id = i+501\n",
    "    print('Review ID %d' %id)\n",
    "    t2, t1 = lda.transform(X[500:510])[i].argsort()[-2:]\n",
    "    print('Top 1:', t1,'Top 2:', t2)\n",
    "    print('-----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8657184c",
   "metadata": {},
   "source": [
    "- Note: \n",
    "I used argsort to find the top two topics of a given review, but argsort( ) can not handle well when there are tied elements in an array.  \n",
    "  \n",
    "    When checking the array of each review, I have noticed that it looks like there are tied elements in a given review when displayed in eight decimals. Take id 1 for example, the array shows as follows:  [[0.01558005, 0.78980687, 0.14787295, 0.01558005, 0.01558005, 0.01558003]]  \n",
    " \n",
    "    While it may  seemed like there are three elements(0.01558005) can be ranked as 2nd, I further used unique( ) function to see if there are really a tie, or it is just because of array decimal display setting.\n",
    " \n",
    "    It turned out that even though some elements looked equal when displayed in eight decimals, they are actually not the same. Therefore, using argsort( ) in the above codes to find top two is still valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b16a030c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(len(np.unique(lda.transform(X[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e76aaae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in range(500,510):\n",
    "    print(len(np.unique(lda.transform(X[i]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb98d2",
   "metadata": {},
   "source": [
    "## 4. Find the top-5 terms (terms with the top-5 highest weights) for each of the 6 topics. Based on those terms, describe what those topics are about. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "5b179d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "quot\n",
      "film\n",
      "wa\n",
      "love\n",
      "ha\n",
      "--------------\n",
      "Topic 1:\n",
      "gt good\n",
      "berry\n",
      "exceeded\n",
      "win competition\n",
      "average price\n",
      "--------------\n",
      "Topic 2:\n",
      "jia\n",
      "fine\n",
      "live\n",
      "star\n",
      "shanghai\n",
      "--------------\n",
      "Topic 3:\n",
      "fifth\n",
      "thonglor\n",
      "located soi\n",
      "forget\n",
      "located\n",
      "--------------\n",
      "Topic 4:\n",
      "delicious\n",
      "food\n",
      "eat\n",
      "restaurant\n",
      "good\n",
      "--------------\n",
      "Topic 5:\n",
      "town\n",
      "old one\n",
      "describe\n",
      "typical\n",
      "south\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(lda.components_):\n",
    "    print('Topic %d:' % i )\n",
    "    # for each topic, get the top 5 terms\n",
    "    for j in topic.argsort()[:-6:-1]:\n",
    "        print(terms[j])\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fb4018",
   "metadata": {},
   "source": [
    "## 5. Based on finding in 3 and 4, describe what review 1 [ID=1] and review 501 [ID=501] are about? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ac0419",
   "metadata": {},
   "source": [
    "- Review 1\n",
    "    Top topics for review 1 are: topic 4 (~0.8) 1 and topic 1 (~0.15). It is clear that this review is talking about how good this restaurant or its food was. In particular, popular terms of these two topics are 'good', 'eat', 'delicious', 'food', 'restaurant', and 'berry'.\n",
    " \n",
    "- Review 501:\n",
    "     Top topic for review 1 is: topic 0 (~0.9). Other topics makes up only 1.6% of the total. This review's main idea is not as clear as review 1. From the popular words in topic 0, it tells us that it is a review about a 'film'. Words like 'love' and 'ha' may indicates a positive attitude toward the film. 'wa' and 'quot'('quote', maybe?) do not provide much information here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
